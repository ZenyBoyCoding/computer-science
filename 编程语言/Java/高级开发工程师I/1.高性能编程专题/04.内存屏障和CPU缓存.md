### CPU性能优化手段-缓存

为了提高程序运行的性能，现代CPU在很多方面对程序进行了优化。

例如:CPU高速缓存。尽可能地避免处理器访问主内存的时间开销，处理器大多会利用缓存(cache)以提高性能。

![缓存结构.png](https://i.loli.net/2021/10/23/qbryKnTzuROfJAl.png)

### 多级缓存

1. `L1 Cache`（一级缓存）是CPU第一层高速缓存，分为数据缓存和指令缓存。一般服务器CPU的L1缓存的容量通常在32-4096`KB`。

2. `L2`由于`L1`级高速缓存容量的限制，为了再次提高CPU的运算速度，在CPU外部放置一高速存储器，即二级缓存。

3. `L3`现在的都是內置的。而它的实际作用即是，`L3`缓存的应用可以进一步降低内存延迟，同时提升大数据量计算时处理器的性能。具有较大`L3`缓存的处理器提供更有效的文件系统缓存行为及较短消息和处理器队列长度。一般是多核共享一个`L3`缓存！

`CPU`在读取数据时，先在`L1`中寻找，再从`L2`寻找，再从`L3`寻找，然后是内存，再后是外存储器。



### 缓存同步协议

多CPU读取同样的数据进行缓存，进行不同运算之后，最终写入主内存以哪个CPU为准？

在这种高速缓存回写的场景下，有一个缓存一致性协议多数CPU厂商对它进行了实现。

`MESI`协议，它规定每条缓存有个状态位，同时定义了下面四个状态:

- 修改态（ `Modified`）---   此 cache行已被修改过（脏行），内容已不同于主存，为此 cache专有
- 专有态（ `Exclusive`）---  此 cache行内容同于主存，但不出现于其它 cache中;
- 共享态（ `Shared`）--- 此 cache行内容同于主存，但也出现于其它 cache中
- 无效态（ `Invalid`）--- 此 cache行内容无效（空行）。

<u>多处理器时，单个CPU对缓存中数据进行了改动，需要通知给其他CPU。也就是意味着，CPU处理要控制自己的读写操作，还要监听其他CPU发出的通知，从而保证**最终一致性**。</u>



### 运行时指令重排

代码：

```java
x = 100;
y = z;
```

正常执行的三个步骤

```java
1、将100写入x
2、读取z的值
3、将z值写入y
```

重排序后执行

```java
1、读取z的值
2、将z的值写入y
3、将100写入x
```

指令重排的场景: **当CPU写缓存时发现缓存区块正被其他CPU占用，为了提高CPU处理性能，可能将后面的读缓存命令优先执行。**并非随便重排，需要遵守**as-if- serial**语义。

`as-if- serial`语乂的意思指:

​		不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器， `runtime`和处理器都必须遵守**as-if- serial**语义。也就是说: **编译器和处理器不会对<u>存在数据依赖关系</u>的操作做重排序。**



### 存在的两个问题

1、CPU高速缓存下有一个问题

​	缓存中的数据与主内存的数据并不是实时同步的，各CPU（或CPU核心）间缓存的数据也不是实时同步。在同一个时间点，各CPU所看到同一内存地址的数据的值可能是不一致的。

2、CPU执行指令重排序优化下有一个问题

​	虽然遵守了`as- if-serial`语义，单仅在单CPU自己执行的情况下能保证结果正确。多核多线程中，指令逻辑无法分辨因果关联，可能岀现**乱序执行**，导致程序运行结果错误。



### 內存屏障

处理器提供了两个内存屏障指令（ `Memory Barrier`）用于解决上述两个问题

**写內存屏障（ Store Memory barrier）:**在指令后插入 Store barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。强制写入主內存，这种显示调用，CPU就不会因为性能考虑而去对指令重排。

**读内存屏障（ Load Memory Barrier）: **在指令前插入 Load Barrier，可以让高速缓存中的数据失效，强制从新从主內存加载数据。强制读取主內存内容，让CPU缓存与主內存保持一致，避免了缓存导致的一致性问题

